{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data(object):\n",
    "    def __init__(self,file,csv_indicator):\n",
    "        self.file = file\n",
    "        self.csv_indicator = csv_indicator\n",
    "        self._load_data()\n",
    "        \n",
    "    def _load_data(self):\n",
    "        if self.csv_indicator==1:\n",
    "            self.df = pd.read_csv(self.file,skiprows=1).drop('ID',1)\n",
    "        else:\n",
    "            self.df = pd.read_excel(self.file,skiprows=1).drop('ID',1)\n",
    "        \n",
    "    \n",
    "    #def _fix_education_values(self):\n",
    "        #column X3 or education should only have values 1-4. \n",
    "        #take out the 5,6,7 values that show up\n",
    "        #what should our methodology be for replacing these values?\n",
    "        #random selection?  Ask Tao what we should do with these values.\n",
    "        #i think randomly selecting a value (1-4) based on actual distribution of column makes sense\n",
    "        #to do this calculate length of distribution w/ acceptable values\n",
    "        #generate random number inside length of that distribution\n",
    "        #index acceptable values by random number you generated\n",
    "        \n",
    "    def _fix_marital_status(self):\n",
    "        #should have 1 (married),2 (single),3 (others)\n",
    "        #replace all 0's with 3 as they will fall under the category \"others\"\n",
    "        self['MARRIAGE']=self['MARRIAGE'].replace(to_replace=0,value=3)\n",
    "        \n",
    "    def _fix_late_pay_status(self,include_columns):\n",
    "        #columns 6-11\n",
    "        #anything negative should be switched to 0. This indicates they have paid on time and in some cases two months early.\n",
    "        for col in ['PAY_0','PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']:\n",
    "            self[col][self[col]<0]=0\n",
    "        #columns 12-17\n",
    "        #this could also be used on these columns. Anything negative indicates they have overpayed. Turn the columns into...\n",
    "        #...money due so replace all negative values.\n",
    "        \n",
    "    def _fix_outliers(self,exclude_columns=None):\n",
    "        def get_outliers(self,value,lower,upper):\n",
    "            if value >= upper + 1.5*upper:\n",
    "                return upper\n",
    "            elif value <= lower - 1.5*lower:\n",
    "                return lower\n",
    "            else:\n",
    "                return value\n",
    "    \n",
    "        if exclude_columns==None:\n",
    "            unique_cols = self.df.columns\n",
    "        else:\n",
    "            unique_cols = self.df.columns.drop(exclude_columns,1)\n",
    "        for i in unique_cols:\n",
    "            lower = self.df[i].quantile(0.225)\n",
    "            upper = self.df[i].quantile(0.775)\n",
    "            self.df[i]= [get_outliers(self,value,lower,upper) \n",
    "                         for value,lower,upper in \n",
    "                         zip(self.df[i],\n",
    "                             [lower for x in range(0,len(self.df))],\n",
    "                             [upper for y in range(0,len(self.df))]\n",
    "                            )\n",
    "                        ]\n",
    "            \n",
    "    \n",
    "    #def _normalize_stuff(self,exclude_columns=None):\n",
    "\n",
    "            \n",
    "            \n",
    "    #def _scale_stuff(self):\n",
    "        \n",
    "    def _calculate_z_scores(self,exclude_columns=None):\n",
    "        if exclude_columns== None:\n",
    "            unique_cols = self.df.columns\n",
    "        else:\n",
    "            unique_cols = self.df.columns.drop(exclude_columns,1)\n",
    "        for col in unique_cols:\n",
    "            self.df[col] = (self.df[col] - self.df[col].mean())/self.df[col].std(ddof=0)\n",
    "    \n",
    "    #def _calculate_x_features():\n",
    "        \n",
    "    #def _calculate_target_variables():\n",
    "        \n",
    "    #def _bin_column_values(column_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = data('default_of_credit_card_clients.xlsx',0)\n",
    "H = data('default_of_credit_card_clients.xlsx',0)\n",
    "#H = data('default_of_credit_card_clients.xlsx',0)\n",
    "\n",
    "categorical = ['SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','default payment next month']\n",
    "\n",
    "F._fix_outliers(categorical)\n",
    "\n",
    "#is the fix outliers function changing the dataframe?\n",
    "F.df.head(15)==H.df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = data('default_of_credit_card_clients.xlsx',0)\n",
    "F._fix_outliers(categorical)\n",
    "F._calculate_z_scores(categorical)\n",
    "F.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMAL WORK FLOW EXAMPLE BELOW\n",
    "\n",
    "#include_columns = [Columns X6-X11]  \n",
    "#include_columns1 = [Columns X12-X17]\n",
    "#categorical = [Categorical Columns]\n",
    "\n",
    "#initialize object\n",
    "F = data('default_of_credit_card_clients.xlsx',0)\n",
    "\n",
    "#F._fix_education_values():      \n",
    "#F._fix_marital_status():\n",
    "#F._fix_late_pay_status(include_columns):\n",
    "#F._fix_late_pay_statues(include_columns1)\n",
    "       \n",
    "    \n",
    "#THEN IN ANY ORDER, TRY DIFFERENT ORDERS OUT TO SEE WHAT WORKS BEST\n",
    "#F._fix_outliers(categorical)\n",
    "#F._normalize_stuff(categorical)\n",
    "#F._scale_stuff(categorical)\n",
    "#F._calculate_z_score(categorical)\n",
    "\n",
    "F.df\n",
    "#use above datdaframe to then test which order produces best modeling performance\n",
    "#take modeling code from evaluation code in competition1 (xgboost model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAY_0 2.8096562336030444  - Highly Positively Skewed\n",
      "PAY_2 2.598798138559056  - Highly Positively Skewed\n",
      "PAY_3 2.856442739149427  - Highly Positively Skewed\n",
      "PAY_4 3.546844839728739  - Highly Positively Skewed\n",
      "PAY_5 3.9663724876742275  - Highly Positively Skewed\n",
      "PAY_6 3.8211940363701076  - Highly Positively Skewed\n",
      "BILL_AMT1 2.6676471957954284  - Highly Positively Skewed\n",
      "BILL_AMT2 2.7074198263435147  - Highly Positively Skewed\n",
      "BILL_AMT3 3.0919755651618455  - Highly Positively Skewed\n",
      "BILL_AMT4 2.8274698840874968  - Highly Positively Skewed\n",
      "BILL_AMT5 2.8802216204313735  - Highly Positively Skewed\n",
      "BILL_AMT6 2.8726836781257115  - Highly Positively Skewed\n",
      "PAY_AMT1 14.667630904439925  - Highly Positively Skewed\n",
      "PAY_AMT2 30.452294738147945  - Highly Positively Skewed\n",
      "PAY_AMT3 17.215774591401207  - Highly Positively Skewed\n",
      "PAY_AMT4 12.904339565339363  - Highly Positively Skewed\n",
      "PAY_AMT5 11.126860673593654  - Highly Positively Skewed\n",
      "PAY_AMT6 10.640195281288497  - Highly Positively Skewed\n",
      "1.5620093548888943\n",
      "1.4068832143681187\n",
      "1.3104755174899048\n",
      "1.3016239251015622\n"
     ]
    }
   ],
   "source": [
    "###Testing scripts for skew handling/normlization\n",
    "\n",
    "\n",
    "file=pd.read_excel('default_of_credit_card_clients.xlsx',header=1)\n",
    "\n",
    "#Find skewness of columns\n",
    "for col in range(6,24):\n",
    "    #Need to set negative values to 0 for square roots to work\n",
    "    file.iloc[:, col][file.iloc[:, col]<0]=0\n",
    "    if abs(scipy.stats.skew(file.iloc[:,col]))<=.5:\n",
    "        print(mean.columns[col],scipy.stats.skew(mean.iloc[:,col]),' - Symmetrical')\n",
    "        pass\n",
    "    elif scipy.stats.skew(file.iloc[:,col])<(-.5) and scipy.stats.skew(file.iloc[:,col]) >=(-1):\n",
    "        print(file.columns[col],scipy.stats.skew(file.iloc[:,col]),' - Moderately Negatively Skewed')\n",
    "    elif scipy.stats.skew(file.iloc[:,col])>.5 and scipy.stats.skew(file.iloc[:,col]) <1:\n",
    "        print(file.columns[col],scipy.stats.skew(file.iloc[:,col]),' - Moderately Positively Skewed')\n",
    "    elif scipy.stats.skew(file.iloc[:,col])<-1:\n",
    "        print(file.columns[col],scipy.stats.skew(file.iloc[:,col]),' - Highly Negatively Skewed')\n",
    "    elif scipy.stats.skew(file.iloc[:,col])>1:\n",
    "        print(file.columns[col],scipy.stats.skew(file.iloc[:,col]),' - Highly Positively Skewed')\n",
    "        \n",
    "\n",
    "#Different methods for handling positive skewness - none seem to be bringing it down enough\n",
    "print(abs(scipy.stats.skew(np.sqrt(file['PAY_0']))))\n",
    "print(abs(scipy.stats.skew(np.cbrt(file['PAY_0']))))\n",
    "print(abs(scipy.stats.skew(np.log(file['PAY_0']+.0001))))\n",
    "print(abs(scipy.stats.skew(1/(file['PAY_0']+.0001))))\n",
    "\n",
    "\n",
    "#Function to automatically test different skew handling techniques and choose the one that minimizes skew\n",
    "#for col in range(6,24):\n",
    "#    minvalue=min(abs(scipy.stats.skew(np.sqrt(file[col]))),abs(scipy.stats.skew(np.cbrt(file[col]))),abs(scipy.stats.skew(np.log(file[col]))))\n",
    "#    if minvalue==abs(scipy.stats.skew(np.sqrt(file[col]))):\n",
    "#        file[col]=np.sqrt(file[col])\n",
    "#    elif minvalue==abs(scipy.stats.skew(np.cbrt(file[col]))):\n",
    "#        file[col]=np.cbrt(file[col])\n",
    "#    elif minvalue==abs(scipy.stats.skew(np.log(file[col]))):\n",
    "#        file[col]=np.log(file[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
